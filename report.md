# **Лабораторна робота №3**

## **Автоматизація систем збірки та розгортання (CI/CD)**

### з дисципліни _“Проект з інтеграції інформаційних систем”_

---

### **Виконав(ла):**

Савицька Вікторія, група ФеІ-44

### **Перевірив:**

Прокопів Р.В.

---

# **1. Мета роботи**

Метою лабораторної роботи є ознайомлення з процесами автоматизації CI/CD.  
Завдання полягало у створенні GitHub Actions пайплайна, який:

- збирає Docker-образ для тренування моделі;
- запускає тренування у контейнері;
- зберігає артефакти (модель, метрики, логи);
- збирає Docker-образ inference-сервера;
- пушить його у GitHub Container Registry;
- запускає контейнер і виконує автоматичний тест `/predict`;
- завантажує метрики інференсу як артефакти;
- підтримує кілька тригерів CI/CD.

---

# **2. Використані технології**

- **GitHub Actions** — автоматизація CI/CD
- **Docker + Buildx** — контейнеризація тренування та інференсу
- **Multi-stage Dockerfile** — оптимізація розміру образу
- **PyTorch + Torchaudio** — тренування моделі
- **Flask API** — інференс-сервіс
- **GitHub Container Registry (GHCR)** — зберігання образів
- **actions/upload-artifact@v4** — артефакти
- **sox** — генерація тестового аудіофайлу

---

# **3. Структура CI/CD пайплайна**

## **3.1. Train Model (train_model)**

Виконує:

- checkout репозиторію
- кешування Docker Buildx шарів
- збірку Dockerfile.train
- запуск контейнера з тренуванням
- збереження артефактів:
  - `best_model.pth`
  - `train.log`
  - `train_metrics.json`
- завантаження `report.md`

---

## **3.2. Build & Push Inference Image**

- завантажує модель з попереднього етапу
- копіює `best_model.pth` у корінь
- збирає multi-stage Dockerfile
- пушить образ у GHCR
- зберігає образ у форматі `inference_image.tar`

---

## **3.3. Test Inference**

- логін у GHCR
- витяг образу
- запуск контейнера з Flask API
- генерує WAV через sox
- виконує `/predict`
- вимірює latency
- зберігає:
  - `inference_metrics.json`
  - `response.json`

---

# **4. Структура Dockerfile**

## **4.1. Dockerfile.train**

- Python 3.10 slim
- встановлення залежностей
- підготовка датасету
- виконання `train.py` з ENV-параметрами
- збереження результатів у `/app/artifacts`

## **4.2. Multi-stage Dockerfile (інференс)**

- **builder stage**: встановлення залежностей
- **runtime stage**: легкий образ з тільки потрібними файлами
- копіювання `best_model.pth`
- запуск Flask API

Це істотно зменшує кінцевий розмір образу.

---

# **5. Тригери workflow**

Підтримуються три типи запусків:

- `push` у master (деплой)
- `pull_request` → master (перевірка)
- ручний запуск — `workflow_dispatch`

---

# **6. Безпека та робота з секретами**

- секрет **CR_PAT** зберігається в `Settings → Secrets → Actions`
- використано `docker/login-action`
- секрети _не зберігаються_ в контейнері або Dockerfile
- використано права `packages: write` для GHCR

---

# **7. Результати роботи пайплайна**

## **7.1. Результати тренування моделі**

Файл: **train_metrics.json**

| Показник                         | Значення        |
| -------------------------------- | --------------- |
| **Епох**                         | 2               |
| **Найкраща валідаційна втрата**  | 0.72219         |
| **Остання валідаційна точність** | 0.7583 (≈75.8%) |
| **Час тренування**               | 38.27 сек       |

### **Історія навчання по епохах**

| Епоха | Train Loss | Train Acc | Val Loss | Val Acc |
| ----- | ---------- | --------- | -------- | ------- |
| 1     | 1.1704     | 0.6124    | 0.7222   | 0.7468  |
| 2     | 0.5526     | 0.8004    | 0.7286   | 0.7583  |

---

## **7.2. Результати інференсу (response.json)**

Модель повернула:

### **Прогноз:**

"prediction": "up"

### **Ймовірності класів:**

| Клас | %         |
| ---- | --------- |
| up   | **55.2%** |
| yes  | 28.1%     |
| no   | 12.8%     |
| down | 3.8%      |

### **Внутрішня затримка (латентність):**

latency_ms: 1 ms

---

## **7.3. Результати тестування inference-сервера (inference_metrics.json)**

| Показник        | Значення |
| --------------- | -------- |
| **HTTP статус** | 200      |
| **latency_ms**  | 19 ms    |

Сервіс працює коректно та швидко.

---
